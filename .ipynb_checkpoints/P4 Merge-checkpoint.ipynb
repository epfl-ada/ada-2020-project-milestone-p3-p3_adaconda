{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone P4 - Creative extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries to use dataframes and basic feartures\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#logistic regression\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "\n",
    "#tool for predictio analysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import auc as computeAUC\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#Radom Forest & Gradient boosting\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the datasets\n",
    "#Civil War Dataset (CWD)\n",
    "DATA_FOLDER = 'data/'\n",
    "DATASET = DATA_FOLDER+\"SambnisImp.csv\"\n",
    "\n",
    "#Terrorism dataset\n",
    "DATASET_TERROR = DATA_FOLDER+\"globalterrorismdb_0919dist.xlsx\"\n",
    "DATASET_CID = DATA_FOLDER+\"Sambanis_cid.dta\"\n",
    "\n",
    "#Opening and loading of files\n",
    "df = pd.read_csv(DATASET, error_bad_lines=False, warn_bad_lines=True)\n",
    "df_t = pd.read_excel(DATASET_TERROR, error_bad_lines=False, warn_bad_lines=True)\n",
    "df_t = df_t.set_index('eventid')\n",
    "\n",
    "#Loading the cowcode dataframe\n",
    "cow = pd.read_csv('data/COW country codes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduction of the CWD to 91 variables + years + cow code\n",
    "doc = df[[\"warstds\", \"year\", \"cowcode\", \"ager\", \"agexp\", \"anoc\", \"army85\", \"autch98\", \"auto4\",\n",
    "    \"autonomy\", \"avgnabo\", \"centpol3\", \"coldwar\", \"decade1\", \"decade2\",\n",
    "    \"decade3\", \"decade4\", \"dem\", \"dem4\", \"demch98\", \"dlang\", \"drel\", \"durable\",\n",
    "    \"ef\", \"ef2\", \"ehet\", \"elfo\", \"elfo2\", \"etdo4590\", \"expgdp\", \"exrec\",\n",
    "    \"fedpol3\", \"fuelexp\", \"gdpgrowth\", \"geo1\", \"geo2\", \"geo34\", \"geo57\",\n",
    "    \"geo69\", \"geo8\", \"illiteracy\", \"incumb\", \"infant\", \"inst\", \"inst3\", \"life\",\n",
    "    \"lmtnest\", \"ln_gdpen\", \"lpopns\", \"major\", \"manuexp\", \"milper\", \"mirps0\",\n",
    "    \"mirps1\", \"mirps2\", \"mirps3\", \"nat_war\", \"ncontig\", \"nmgdp\", \"nmdp4_alt\",\n",
    "    \"numlang\", \"nwstate\", \"oil\", \"p4mchg\", \"parcomp\", \"parreg\", \"part\",\n",
    "    \"partfree\", \"plural\", \"plurrel\", \"pol4\", \"pol4m\", \"pol4sq\", \"polch98\",\n",
    "    \"polcomp\", \"popdense\", \"presi\", \"pri\", \"proxregc\", \"ptime\", \"reg\",\n",
    "    \"regd4_alt\", \"relfrac\", \"seceduc\", \"second\", \"semipol3\", \"sip2\", \"sxpnew\",\n",
    "    \"sxpsq\", \"tnatwar\", \"trade\", \"warhist\", \"xconst\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dataframes according to the parameters that were taken into account by the different papers\n",
    "\n",
    "#Fearon and Laitin (2003)\n",
    "df2003 = doc [[\"warhist\", \"ln_gdpen\", \"lpopns\", \"lmtnest\",\n",
    "    \"ncontig\", \"oil\", \"nwstate\", \"inst3\", \"pol4\", \"ef\", \"relfrac\"]]\n",
    "\n",
    "#Collier and Hoeffler (2004)\n",
    "df2004 = doc[[\"sxpnew\", \"sxpsq\", \"ln_gdpen\", \"gdpgrowth\",\n",
    "    \"warhist\", \"lmtnest\", \"ef\", \"popdense\", \"lpopns\", \"coldwar\", \"seceduc\",\n",
    "    \"ptime\"]]\n",
    "\n",
    "#Hegre and Sambanis (2006)\n",
    "df2006 = doc[[\"lpopns\", \"ln_gdpen\", \"inst3\", \"parreg\", \"geo34\",\n",
    "    \"proxregc\", \"gdpgrowth\", \"anoc\", \"partfree\", \"nat_war\", \"lmtnest\",\n",
    "    \"decade1\", \"pol4sq\", \"nwstate\", \"regd4_alt\", \"etdo4590\", \"milper\", \"geo1\",\n",
    "    \"tnatwar\", \"presi\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the y parameter wich is the occurence of a civil war => warstds\n",
    "y = doc[\"warstds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that will plot ROC curves of different sets of data that have undergo a n fold cross validation\n",
    "#The variable: model is the classifier or model that we want to observe\n",
    "#Each is a variable that allow the plot of every ROC curves\n",
    "def rocList(model,Xs,Ys,n=10,labels = [] ,each=False,newplot=True,displaymean = True):\n",
    "    \n",
    "    means_x=[]\n",
    "    means_y=[]\n",
    "    means_auc=[]\n",
    "    for j in range(len(Ys)) :\n",
    "        x=Xs[j]\n",
    "        y=Ys[j]\n",
    "    \n",
    "        #Objects to store the calculated tpr (true positive rate), fpr(false positive rate) and auc (area under curve)\n",
    "        tprs = []\n",
    "        aucs = []\n",
    "        mean_fpr = np.linspace(0, 1, 100)\n",
    "        kf = StratifiedKFold(n_splits=n)\n",
    "        kf.split(x,y) \n",
    "\n",
    "        #fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "        #For each fold, calculate the ROC-parametres (tpr, fpr and auc) and plot\n",
    "        for i, (train_index, test_index) in enumerate(kf.split(x,y)):\n",
    "            X_train, X_test = x.iloc[train_index], x.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            classifier  = model.fit(X_train, y_train)\n",
    "            clf.fit(X_train,y_train)\n",
    "            predictions = clf.predict_proba(X_test)[:,-1]\n",
    "            falseRate, trueRate, threshold = metrics.roc_curve(y_test, predictions)\n",
    "            interp_tpr = np.interp(mean_fpr, falseRate, trueRate)            \n",
    "            interp_tpr[0] = 0.0\n",
    "            tprs.append(interp_tpr)\n",
    "            #aucs.append( metrics.auc(falseRate, trueRate) )\n",
    "            #aucs.append( metrics.roc_auc_score(y_test, predictions) )\n",
    "\n",
    "        #Calculate the mean and standard deviation of ROC-parametres\n",
    "        mean_tpr = np.nanmean(tprs, axis=0)\n",
    "        mean_tpr[-1] = 1.0\n",
    "        mean_auc = computeAUC(mean_fpr, mean_tpr)\n",
    "        #std_auc = np.nanstd(aucs)\n",
    "        \n",
    "        means_x.append(mean_fpr)\n",
    "        means_y.append(mean_tpr)\n",
    "        means_auc.append(mean_auc)\n",
    "        \n",
    "        if(each):\n",
    "            plt.figure(figsize=(10,10))\n",
    "            #plt.plot([0, 1], [0, 1], linestyle='-', lw=2, color='k',\n",
    "            #    label='Chance', alpha=.8)\n",
    "            plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "                #label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "                lw=2, alpha=.8)\n",
    "            std_tpr = np.std(tprs, axis=0)\n",
    "            tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "            tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "            plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                        label=r'$\\pm$ 1 std. dev.')\n",
    "            plt.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
    "                   title=\"\")\n",
    "            plt.legend(loc=\"lower right\")\n",
    "            plt.show()\n",
    "    \n",
    "    if(len(labels)!=len(means_x)):\n",
    "        labels = ['']*len(means_x)\n",
    "    \n",
    "    if (newplot): \n",
    "        plt.figure(figsize=(15,10))\n",
    "    plt.title(\"Comparison of predictions from different datasets with a ROC plot\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    #plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',label='Chance', alpha=.8)\n",
    "\n",
    "    for i in range(len(means_x)):\n",
    "        plt.plot(means_x[i],means_y[i],alpha = 0.8,label= labels[i] +' AUC: ' + str(round(means_auc[i],3)))\n",
    "    over_x = np.mean( means_x ,axis = 0 )\n",
    "    over_y = np.mean( means_y ,axis = 0 )\n",
    "    if (displaymean): plt.plot( over_x , over_y , 'k--' , label = 'Global Mean , AUC: ' + str(round(metrics.auc(over_x, over_y),3))  )\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column of the evolution of a feature (must be numbers) by country, year to year\n",
    "#return vector of this evolution --> df['feature']= computeEvol(df,feature)\n",
    "#needs the column 'year' & 'cowcode'\n",
    "def computeEvol(df,feature):\n",
    "    cow = df['cowcode'].unique()\n",
    "    relative=[0]*len(df)\n",
    "    for country in cow:\n",
    "        tabCountry = df[ df['cowcode']==country ].sort_values(by='year')\n",
    "        for year in tabCountry['year'].unique()[1:]:\n",
    "            before = tabCountry[ tabCountry['year'] == year-1 ][feature].values[0]\n",
    "            after = tabCountry[ tabCountry['year'] == year ][feature].values[0]\n",
    "            if(before==0):\n",
    "                ratio = 0\n",
    "            else:ratio = (after-before)/before\n",
    "            ind=df.loc[ (df['year'] == year) & (df['cowcode'] == country) ].index.values[0] \n",
    "            relative[ind]=ratio\n",
    "    return relative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The goal of this cell is to add a columns with the name of the country then to introduce the terrorism data\n",
    "#Note: we can then drop StateName column\n",
    "#dropuseless column and change names of the 2 remaining\n",
    "cow=cow.drop(['StateAbb'],axis=1)\n",
    "cow.columns = ['cowcode','country']\n",
    "#merge it to doc (into doc_t) that now have a column 'StateName' matching cow code\n",
    "doc_t = doc.merge(cow)\n",
    "#doc_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of countries in the dataset : 1004\n"
     ]
    }
   ],
   "source": [
    "#Get a list of country and their code (index) for the terrorism dataset\n",
    "country = df_t[[\"country\", \"country_txt\"]]\n",
    "maxval = df_t['country'].max()\n",
    "print(\"Total number of countries in the dataset : \" + str(maxval))\n",
    "\n",
    "lst=[]\n",
    "for i in range(maxval):\n",
    "    temp = country[country.country == i]\n",
    "    if(not temp.empty):\n",
    "        temp1=country[country.country == i].iloc[0]\n",
    "        lst.append(temp1.country_txt)\n",
    "    else:\n",
    "        #not a country\n",
    "        lst.append(\"NAC\")\n",
    "countrylist = pd.DataFrame(lst)\n",
    "#countrylist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate number of terrorist attacks in each country for each year. Final dataframe is fy1 which contains all years from\n",
    "#1970 to 2000 with all countries and their number of terrorist attacks\n",
    "#new = df_t[(df_t.country == 200)]\n",
    "#new.head()\n",
    "#import sys\n",
    "first = df_t[df_t['iyear']==1970]\n",
    "#nb = len(df_t[(df_t.iyear==1970 & df_t.country == 200)])\n",
    "fc = first[first['country']==200]\n",
    "maxval = df_t['country'].max()\n",
    "#print(maxval)\n",
    "#create the index for each year from 1970 to 2000\n",
    "fy = np.arange(1970, 2000, 1)\n",
    "fy1 = pd.DataFrame(fy,columns=['year'])\n",
    "fy1 = fy1.set_index('year')\n",
    "#length = len(df_t[(df_t.country==1)])\n",
    "#print(length)\n",
    "for i in range(maxval):\n",
    "    ls=[]\n",
    "    for j in range(1970,2000):\n",
    "        temp = df_t[(df_t.country==i)]\n",
    "        temp2 = len(temp[(temp.iyear==j)])\n",
    "        ls.append(temp2)\n",
    "    fy1[i] = ls\n",
    "    \n",
    "fy1.columns = [countrylist[0]]\n",
    "fy1.drop(list(fy1.filter(regex = 'NAC')), axis = 1, inplace = True)\n",
    "#fy1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmp is a vector of zeros\n",
    "tmp = [0]*len(doc_t)\n",
    "#we iterate on our dataframe (doc_t) and retrieve for each row the year and the country\n",
    "#then if the values is present in fy1 (we verfy in index and column), the value is changed at the correspondign location in tmp\n",
    "for index, row in doc_t.iterrows():\n",
    "    year = row['year']\n",
    "    country = row['country']\n",
    "    if( (year in fy1.index) & (country in fy1.columns) ):\n",
    "        tmp[index]= fy1.loc[year][country].values[0]\n",
    "#finally tmp is placed in doc_t as terrorism column\n",
    "doc_t['terrorism']=tmp\n",
    "doc_t=doc_t.drop(['country'],axis=1)\n",
    "#doc_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'newdoc_t = doc_t[[\"warstds\", \"year\", \"cowcode\", \"ager\", \"agexp\", \"anoc\", \"army85\", \"autch98\", \"auto4\",\\n    \"autonomy\", \"avgnabo\", \"centpol3\", \"coldwar\", \"decade1\", \"decade2\",\\n    \"decade3\", \"decade4\", \"dem\", \"dem4\", \"demch98\", \"dlang\", \"drel\", \"durable\",\\n    \"ef\", \"ef2\", \"ehet\", \"elfo\", \"elfo2\", \"etdo4590\", \"expgdp\", \"exrec\",\\n    \"fedpol3\", \"fuelexp\", \"gdpgrowth\", \"geo1\", \"geo2\", \"geo34\", \"geo57\",\\n    \"geo69\", \"geo8\", \"illiteracy\", \"incumb\", \"infant\", \"inst\", \"inst3\", \"life\",\\n    \"lmtnest\", \"ln_gdpen\", \"lpopns\", \"major\", \"manuexp\", \"milper\", \"mirps0\",\\n    \"mirps1\", \"mirps2\", \"mirps3\", \"nat_war\", \"ncontig\", \"nmgdp\", \"nmdp4_alt\",\\n    \"numlang\", \"nwstate\", \"oil\", \"p4mchg\", \"parcomp\", \"parreg\", \"part\",\\n    \"partfree\", \"plural\", \"plurrel\", \"pol4\", \"pol4m\", \"pol4sq\", \"polch98\",\\n    \"polcomp\", \"popdense\", \"presi\", \"pri\", \"proxregc\", \"ptime\", \"reg\",\\n    \"regd4_alt\", \"relfrac\", \"seceduc\", \"second\", \"semipol3\", \"sip2\", \"sxpnew\",\\n    \"sxpsq\", \"tnatwar\", \"trade\", \"warhist\", \"xconst\", \"terrorism\"]]'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''newdoc_t = doc_t[[\"warstds\", \"year\", \"cowcode\", \"ager\", \"agexp\", \"anoc\", \"army85\", \"autch98\", \"auto4\",\n",
    "    \"autonomy\", \"avgnabo\", \"centpol3\", \"coldwar\", \"decade1\", \"decade2\",\n",
    "    \"decade3\", \"decade4\", \"dem\", \"dem4\", \"demch98\", \"dlang\", \"drel\", \"durable\",\n",
    "    \"ef\", \"ef2\", \"ehet\", \"elfo\", \"elfo2\", \"etdo4590\", \"expgdp\", \"exrec\",\n",
    "    \"fedpol3\", \"fuelexp\", \"gdpgrowth\", \"geo1\", \"geo2\", \"geo34\", \"geo57\",\n",
    "    \"geo69\", \"geo8\", \"illiteracy\", \"incumb\", \"infant\", \"inst\", \"inst3\", \"life\",\n",
    "    \"lmtnest\", \"ln_gdpen\", \"lpopns\", \"major\", \"manuexp\", \"milper\", \"mirps0\",\n",
    "    \"mirps1\", \"mirps2\", \"mirps3\", \"nat_war\", \"ncontig\", \"nmgdp\", \"nmdp4_alt\",\n",
    "    \"numlang\", \"nwstate\", \"oil\", \"p4mchg\", \"parcomp\", \"parreg\", \"part\",\n",
    "    \"partfree\", \"plural\", \"plurrel\", \"pol4\", \"pol4m\", \"pol4sq\", \"polch98\",\n",
    "    \"polcomp\", \"popdense\", \"presi\", \"pri\", \"proxregc\", \"ptime\", \"reg\",\n",
    "    \"regd4_alt\", \"relfrac\", \"seceduc\", \"second\", \"semipol3\", \"sip2\", \"sxpnew\",\n",
    "    \"sxpsq\", \"tnatwar\", \"trade\", \"warhist\", \"xconst\", \"terrorism\"]]'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### terrorism study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute terrorism evolution\n",
    "doc_t2 = doc_t.copy()\n",
    "doc_t2['evolterrorism']= computeEvol(doc_t2,'terrorism')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['country'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-c9dd0c63d57a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'warstds'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#terrorism data set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mX_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"warstds\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"year\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"cowcode\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'country'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0my_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc_t\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'warstds'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3995\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3996\u001b[0m             \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3997\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3998\u001b[0m         )\n\u001b[0;32m   3999\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3934\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3935\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3936\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3938\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3968\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3969\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3970\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3971\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5016\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5017\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5018\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5019\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5020\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['country'] not found in axis\""
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "\n",
    "#original data set\n",
    "X = doc.drop( [\"warstds\", \"year\", \"cowcode\"] , axis=1 )\n",
    "y = doc['warstds']\n",
    "#terrorism data set\n",
    "X_t = doc_t.drop( [\"warstds\", \"year\", \"cowcode\"] , axis=1 )\n",
    "y_t = doc_t['warstds']\n",
    "\n",
    "#original data set from 1970\n",
    "X70 = doc[ doc['year'] >= 1970 ].drop( [\"warstds\", \"year\", \"cowcode\"] , axis=1 )\n",
    "y70 = doc[ doc['year'] >= 1970 ]['warstds']\n",
    "#terrorism data set from 1970\n",
    "X_t70 = doc_t[ doc_t['year'] >= 1970 ].drop( [\"warstds\", \"year\", \"cowcode\"] , axis=1 )\n",
    "y_t70 = doc_t[ doc_t['year'] >= 1970 ]['warstds']\n",
    "\n",
    "##test with terrorism evolution\n",
    "#terrorism data set with terrorism evolution\n",
    "X_t_ev = doc_t2.drop( [\"warstds\", \"year\", \"cowcode\",'country','terrorism'] , axis=1 )\n",
    "y_t_ev = doc_t2['warstds']\n",
    "\n",
    "#same from 1970\n",
    "X_t_ev70 = doc_t2[ doc_t2['year'] >= 1970 ].drop( [\"warstds\", \"year\", \"cowcode\",'terrorism'] , axis=1 )\n",
    "y_t_ev70 = doc_t2[ doc_t2['year'] >= 1970 ]['warstds']\n",
    "\n",
    "Xs = [ X , X_t, X_t_ev , X70 , X_t70 ,X_t_ev70 ,  ]\n",
    "Ys = [ y , y_t, y_t_ev , y70 , y_t70 ,y_t_ev70 ,  ]\n",
    "\n",
    "labs =['original dataset all','with terrorism all ', 'with evolution of terrorism all',\n",
    "       'original dataset 70','with terrorism 70', 'with evolution of terrorism 70',\n",
    "       ]\n",
    "\n",
    "rocList(clf,Xs,Ys,n=10,labels = labs,displaymean = False)\n",
    "\n",
    "plt.plot([0,1],[0,1],'k--',alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Gini Score ranking\n",
    "\n",
    "#all years\n",
    "X = doc_t2.drop( [\"warstds\", \"year\", \"cowcode\",'country'] , axis=1 )\n",
    "y = doc_t2['warstds']\n",
    "clf.fit(X,y)\n",
    "#then i match the feature with their importance (aka Gini Score) provided by the Random Forest object\n",
    "testDF = pd.DataFrame ( { 'variables' : X.columns ,\n",
    "                          'importance': clf.feature_importances_  ,\n",
    "                              }  )    \n",
    "#i order the features according to their importance, and keep only the 20 best\n",
    "testDF = testDF.sort_values(by=['importance'] , ascending=False)\n",
    "testDF = testDF.reset_index() \n",
    "ind_ft = testDF.loc[ testDF['variables'] == 'terrorism'].index[0]\n",
    "ind_evol = testDF.loc[ testDF['variables'] == 'evolterrorism'].index[0]\n",
    "\n",
    "print( 'terrorism rank (all): '+str(ind_ft) )\n",
    "print( 'evolterrorism rank (all): '+str(ind_evol) )\n",
    "\n",
    "#1970-2000\n",
    "X = doc_t2[ doc_t2['year'] >= 1970 ].drop( [\"warstds\", \"year\", \"cowcode\",'country'] , axis=1 )\n",
    "y = doc_t2[ doc_t2['year'] >= 1970 ]['warstds']\n",
    "\n",
    "clf.fit(X,y)\n",
    "\n",
    "#then i match the feature with their importance (aka Gini Score) provided by the Random Forest object\n",
    "testDF = pd.DataFrame ( { 'variables' : X.columns ,\n",
    "                          'importance': clf.feature_importances_  ,\n",
    "                              }  )\n",
    "    \n",
    "#i order the features according to their importance, and keep only the 20 best\n",
    "testDF = testDF.sort_values(by=['importance'] , ascending=False)\n",
    "testDF = testDF.reset_index()\n",
    "    \n",
    "ind_ft = testDF.loc[ testDF['variables'] == 'terrorism'].index[0]\n",
    "ind_evol = testDF.loc[ testDF['variables'] == 'evolterrorism'].index[0]\n",
    "\n",
    "print( 'terrorism rank (70): ' + str(ind_ft) )\n",
    "print( 'evolterrorism rank (70): ' + str(ind_evol) )\n",
    "\n",
    "## best rank for evolterrorism from 1970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting of the training set and testing set, Creation of the y training and y testing\n",
    "#Removing of the \"warstds\" which is the variable we want to predict so it should be erased from the X training and X testing\n",
    "#CWD\n",
    "training_set,testing_set, y_train, y_test = train_test_split( doc.drop([\"warstds\", \"year\", \"cowcode\"],axis=1) , doc[\"warstds\"], test_size=0.33,)\n",
    "training_set_t,testing_set_t, y_train_t, y_test_t = train_test_split( doc_t.drop([\"warstds\", \"year\", \"cowcode\"],axis=1) , doc_t[\"warstds\"], test_size=0.33,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncorrected Logistic regression with the parameters solver and max_iter because the number of iterations were not enough\n",
    "#Fearon and Laitin (2003)\n",
    "log2003 = LogisticRegression(penalty = 'none', solver='lbfgs', max_iter=1e9).fit(df2003,y)\n",
    "\n",
    "#Collier and Hoeffler (2004)\n",
    "log2004 = LogisticRegression(penalty = 'none', solver='lbfgs', max_iter=1e9).fit(df2004,y)\n",
    "\n",
    "#Hegre and Sambanis (2006)\n",
    "log2006 = LogisticRegression(penalty = 'none', solver='lbfgs', max_iter=1e9).fit(df2006,y)\n",
    "\n",
    "#Creation of a Random Forest classifier with max_depth = 10 for CWD\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "\n",
    "#Creation of a Gradient Boosting Classifier with the same variables as Random Forest\n",
    "boostclf = GradientBoostingClassifier(n_estimators=100, max_depth=10)\n",
    "\n",
    "#Creation of a Random Forest classifier with max_depth = 10 for CWD + TD\n",
    "clf_t = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "\n",
    "#Creation of a Gradient Boosting Classifier with the same variables as Random Forest for CWD + TD\n",
    "\n",
    "boostclf_t = GradientBoostingClassifier(n_estimators=100, max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=10,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the RF model with the CWD training set\n",
    "clf.fit(training_set, y_train)\n",
    "\n",
    "#Fitting the GB model with the CWD training set\n",
    "boostclf.fit(training_set, y_train)\n",
    "\n",
    "#Fitting the RF model with the CWD + DT training set\n",
    "clf_t.fit(training_set_t, y_train_t)\n",
    "\n",
    "#Fitting the GB model with the CWD + DT training set\n",
    "boostclf_t.fit(training_set_t, y_train_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculations of the estimates and the AUC score\n",
    "#Fearon and Laitin (2003)\n",
    "probs = log2003.predict_proba(df2003)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "#Collier and Hoeffler (2004)\n",
    "probs4 = log2004.predict_proba(df2004)\n",
    "preds4 = probs4[:,1]\n",
    "fpr4, tpr4, threshold4 = metrics.roc_curve(y, preds4)\n",
    "roc_auc4 = metrics.auc(fpr4, tpr4)\n",
    "\n",
    "#Hegre and Sambanis (2006)\n",
    "probs6 = log2006.predict_proba(df2006)\n",
    "preds6 = probs6[:,1]\n",
    "fpr6, tpr6, threshold6 = metrics.roc_curve(y, preds6)\n",
    "roc_auc6 = metrics.auc(fpr6, tpr6)\n",
    "\n",
    "#Predictions with the testing set, calculations of the AUC scores for the RF model\n",
    "probs0c = clf.predict_proba(testing_set)\n",
    "preds0c = probs0c[:,1]\n",
    "fpr0c, tpr0c, threshold0c = metrics.roc_curve(y_test, preds0c)\n",
    "roc_auc0c = metrics.auc(fpr0c, tpr0c)\n",
    "\n",
    "#Predictions with the testing set, calculations of the AUC scores for the GB model\n",
    "probs0bc = boostclf.predict_proba(testing_set)\n",
    "preds0bc = probs0bc[:,1]\n",
    "fpr0bc, tpr0bc, threshold0bc = metrics.roc_curve(y_test, preds0bc)\n",
    "roc_auc0bc = metrics.auc(fpr0bc, tpr0bc)\n",
    "\n",
    "#Predictions with the testing set, calculations of the AUC scores for the RF model for CWD + TD\n",
    "probs0c_t = clf_t.predict_proba(testing_set_t)\n",
    "preds0c_t = probs0c_t[:,1]\n",
    "fpr0c_t, tpr0c_t, threshold0c_t = metrics.roc_curve(y_test_t, preds0c_t)\n",
    "roc_auc0c_t = metrics.auc(fpr0c_t, tpr0c_t)\n",
    "\n",
    "#Predictions with the testing set, calculations of the AUC scores for CWD + TD\n",
    "probs0bc_t = boostclf_t.predict_proba(testing_set_t)\n",
    "preds0bc_t = probs0bc_t[:,1]\n",
    "fpr0bc_t, tpr0bc_t, threshold0bc_t = metrics.roc_curve(y_test_t, preds0bc_t)\n",
    "roc_auc0bc_t = metrics.auc(fpr0bc_t, tpr0bc_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting of the curves with a red dashed line like in ROC plots\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.title('Comparison of different models predictions')\n",
    "\n",
    "#Plotting of the 3 LR models\n",
    "plt.plot(fpr, tpr, 'b', label = 'Fearon and Laitin (2003), '+'AUC = ' + '{:.2f}'.format(roc_auc)) \n",
    "plt.plot(fpr4, tpr4, 'green', label = 'Collier and Hoeffler (2004), '+'AUC = ' + '{:.2f}'.format( roc_auc4))\n",
    "plt.plot(fpr6, tpr6, 'purple', label = 'Hegre and Sambanis (2006), '+'AUC = ' + '{:.2f}'.format( roc_auc6)) \n",
    "\n",
    "#Plotting of the RF and GB models\n",
    "rocList(clf,[doc.drop([\"warstds\", \"year\", \"cowcode\"],axis=1)] , [doc[\"warstds\"]], labels = ['Random Forest over 91 features'], newplot = False, displaymean = False)\n",
    "rocList(boostclf,[doc.drop([\"warstds\", \"year\", \"cowcode\"],axis=1)] , [doc[\"warstds\"]], labels = ['GradientBoosting over 91 features'], newplot = False, displaymean = False)\n",
    "\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a Series of features importances or gini scores of the models (RF and GB)\n",
    "feature_imp = pd.Series(clf.feature_importances_,index=training_set.columns).sort_values(ascending=False)\n",
    "boost_feature_imp = pd.Series(boostclf.feature_importances_,index=training_set.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Comparison of the features importance for the two models (RF and GB)\n",
    "fig, ax = plt.subplots(1,2, figsize = (20,25))\n",
    "#plt.figure(figsize = (20, 15))\n",
    "sns.barplot(ax = ax[0],x=boost_feature_imp, y=boost_feature_imp.index)\n",
    "# Add labels to your graph\n",
    "#ax[0].xlabel('Feature Importance Score')\n",
    "#ax[0].ylabel('Features')\n",
    "#ax[0].title(\"Visualizing Important Features\")\n",
    "sns.barplot(ax = ax[1],x=feature_imp, y=feature_imp.index)\n",
    "# Add labels to your graph\n",
    "#ax[1].xlabel('Feature Importance Score')\n",
    "#ax[1].ylabel('Features')\n",
    "#ax[1].title(\"Visualizing Important Features\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,20))\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "sns.barplot(x=boost_feature_imp, y=boost_feature_imp.index)\n",
    "\n",
    "sns.barplot(x=-feature_imp, y=feature_imp.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC plots of the 3 LR, the RF and GB on CWD\n",
    "#ROC plots of the RF and GB on CWD + TD\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.title('Comparison of different models predictions')\n",
    "plt.plot(fpr, tpr, 'b', label = 'Fearon and Laitin (2003), '+'AUC = ' + '{:.2f}'.format(roc_auc)) \n",
    "plt.plot(fpr4, tpr4, 'green', label = 'Collier and Hoeffler (2004), '+'AUC = ' + '{:.2f}'.format( roc_auc4))\n",
    "plt.plot(fpr6, tpr6, 'purple', label = 'Hegre and Sambanis (2006), '+'AUC = ' + '{:.2f}'.format( roc_auc6)) \n",
    "rocList(clf,[doc.drop([\"warstds\", \"year\", \"cowcode\"],axis=1)] , [doc[\"warstds\"]], labels = ['RF over 91 feat.'], newplot = False, displaymean = False)\n",
    "rocList(boostclf,[doc.drop([\"warstds\", \"year\", \"cowcode\"],axis=1)] , [doc[\"warstds\"]], labels = ['GB over 91 feat.'], newplot = False, displaymean = False)\n",
    "rocList(clf_t,[doc_t.drop([\"warstds\", \"year\", \"cowcode\"],axis=1)] , [doc_t[\"warstds\"]], labels = ['RF over 92 feat.(+terrorism)'], newplot = False, displaymean = False)\n",
    "rocList(boostclf_t,[doc_t.drop([\"warstds\", \"year\", \"cowcode\"],axis=1)] , [doc_t[\"warstds\"]], labels = ['GB over 92 feat.(+terrorism)'], newplot = False, displaymean = False)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],color='k',alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram to see the repartition of the values accross the years\n",
    "#We see that there are twice as many variables in the 1990-2000 than in 1950-1960\n",
    "doc['year'].hist(bins=55)\n",
    "#quantiles, we can use then instead of period for slicing to have less unbalanced sub df\n",
    "qt = doc['year'].quantile(np.arange(0,1.1,0.1))\n",
    "for q in qt:\n",
    "    plt.axvline(x=q,color='k')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing the Dataset into subsets according to a number of years (period)\n",
    "period = 5\n",
    "vecy=np.arange(1945,2000-period,period)\n",
    "tab = []\n",
    "for year in vecy:\n",
    "    tab.append( doc[ (doc['year'] >= year) & (doc['year'] < year+period) ] )\n",
    "\n",
    "tab.append(doc[ doc['year'] >= 2000-period ])\n",
    "\n",
    "for i in range(len(tab)):\n",
    "    tab[i] = tab[i].drop(['year','cowcode'] , axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting of the ROC curve: means of the n cross-validation of each subset (period of time)\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "xs=[]\n",
    "ys=[]\n",
    "for i in tab:\n",
    "    ys.append( i['warstds'] )\n",
    "    xs.append( i.drop(['warstds'],axis='columns') )\n",
    "labs=[]\n",
    "tmpvec = np.arange(1945,2000,period)\n",
    "for year in tmpvec:\n",
    "    labs.append( str(year)+'-'+str(year+period) )\n",
    "#print(len(labs))\n",
    "rocList(clf,xs,ys,n=5,labels=labs)\n",
    "plt.plot(fpr0c, tpr0c, 'black', label = 'Random Forest over 91 features, '+'AUC = ' + '{:.2f}'.format( roc_auc0c))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GDP per capita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization of the repartition of the values according to GDP per capita\n",
    "#We need to use quantiles\n",
    "docbis = doc.copy()\n",
    "doc['nmgdp'].hist(bins=100)\n",
    "quantile = docbis['nmgdp'].quantile(np.arange(0,1.1,0.1))\n",
    "for q in quantile:\n",
    "    plt.axvline(x=q,color='k')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cutting the dataset into subsets by quantiles\n",
    "quantile_nmgdp = docbis['nmgdp'].quantile(np.arange(0,1.1,0.1))\n",
    "tab_nmgdp=[]\n",
    "for i in range(10):\n",
    "    tab_nmgdp.append( doc[ (docbis['nmgdp'] >= quantile_nmgdp.iloc[i]) & (doc['nmgdp'] < quantile_nmgdp.iloc[i+1]) ] )\n",
    "\n",
    "for i in range(len(tab_nmgdp)):\n",
    "    tab_nmgdp[i] = tab_nmgdp[i].drop(['year','cowcode'] , axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tab_nmgdp:\n",
    "    print(len(i[i['warstds']==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_nmgdp=[]\n",
    "ys_nmgdp=[]\n",
    "tab_nmgdp = tab_nmgdp[:5]\n",
    "for i in tab_nmgdp:\n",
    "    ys_nmgdp.append( i['warstds'] )\n",
    "    xs_nmgdp.append( i.drop(['warstds'],axis='columns') )\n",
    "#labs=[]\n",
    "'''tmpvec = np.arange(1945,2000,period)\n",
    "for year in tmpvec:\n",
    "    labs.append( str(year)+'-'+str(year+period) )'''\n",
    "#print(len(labs))\n",
    "labs_nmgdp = ['1','2','3','4','5','6','7','8','9','10']\n",
    "rocList(clf,xs_nmgdp,ys_nmgdp,n=5,labels=labs_nmgdp)\n",
    "#plt.plot(fpr0c, tpr0c, 'black', label = 'Random Forest over 91 features, '+'AUC = ' + '{:.2f}'.format( roc_auc0c))\n",
    "#plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPD Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization of the repartition of the values according to GDP Growth\n",
    "doc['gdpgrowth'].hist(bins=100)\n",
    "\n",
    "quantile = doc['gdpgrowth'].quantile(np.arange(0,1.1,0.1))\n",
    "for q in quantile:\n",
    "    plt.axvline(x=q,color='k')\n",
    "\n",
    "#log scale\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cutting the dataset into subsets by quantile\n",
    "quantile_gdpgrowth = docbis['gdpgrowth'].quantile(np.arange(0,1.1,0.1))\n",
    "tab_gdpgrowth=[]\n",
    "for i in range(10):\n",
    "    tab.append( doc[ (docbis['gdpgrowth'] >= quantile_gdpgrowth.iloc[i]) & (doc['gdpgrowth'] < quantile_gdpgrowth.iloc[i+1]) ] )\n",
    "\n",
    "for i in range(len(tab_gdpgrowth)):\n",
    "    tab_gdpgrowth[i] = tab_ngdpgrowth[i].drop(['year','cowcode'] , axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_gdpgrowth=[]\n",
    "ys_gdpgrowth=[]\n",
    "for i in tab_nmgdp:\n",
    "    ys_gdpgrowth.append( i['warstds'] )\n",
    "    xs_gdpgrowth.append( i.drop(['warstds'],axis='columns') )\n",
    "rocList(clf,xs_gdpgrowth,ys_gdpgrowth,n=5,labels=labs_nmgdp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test nmgdp == gdp per capita\n",
    "cow = doc['cowcode'].unique()\n",
    "\n",
    "relative=[0]*len(doc)\n",
    "for country in cow:\n",
    "    tmp = doc[ doc['cowcode']==country ].sort_values(by='year')\n",
    "    for year in tmp['year'].unique()[1:]:\n",
    "        before = tmp[ tmp['year'] == year-1 ]['nmgdp'].values[0]\n",
    "        after = tmp[ tmp['year'] == year ]['nmgdp'].values[0]\n",
    "        ratio = (after-before)/before \n",
    "        ind=doc.loc[ (doc['year'] == year) & (doc['cowcode'] == country) ].index.values[0] \n",
    "        relative[ind]=ratio\n",
    "doc['evolnmgdp'] = relative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc['evolnmgdp'] = computeEvol(doc,'nmgdp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "for country in cow:\n",
    "    tmp = doc[ doc['cowcode']==country ].sort_values(by='year')\n",
    "    plt.plot( tmp['year'] , tmp['evolnmgdp'])\n",
    "    \n",
    "plt.title('relative gdp per capita evolution for each country')\n",
    "plt.figure(figsize=(15,5))\n",
    "for country in cow:\n",
    "    tmp = doc[ doc['cowcode']==country ].sort_values(by='year')\n",
    "    plt.plot( tmp['year'] , tmp['nmgdp'])\n",
    "plt.title('gdp per capita evolution for each country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_evol=doc.copy()\n",
    "features=['nmgdp','gdpgrowth','life','infant','expgdp','popdense','illiteracy']\n",
    "features=['nmgdp','life','infant','expgdp','popdense','illiteracy']\n",
    "for ft in features:\n",
    "    doc_evol['evol'+ft] = computeEvol(doc_evol,ft)\n",
    "\n",
    "#on retire les variables inutiles à la prediction\n",
    "X = doc_evol.drop(['warstds','year','cowcode'] , axis='columns')\n",
    "y = doc_evol['warstds']\n",
    "\n",
    "#perform Random Forest mothod on the data\n",
    "clf = RandomForestClassifier(n_estimators=100,max_depth=10)\n",
    "clf.fit(X,y)\n",
    "\n",
    "#then i match the feature with their importance (aka Gini Score) provided by the Random Forest object\n",
    "testDF = pd.DataFrame ( { 'variables' : X.columns ,\n",
    "                          'importance': clf.feature_importances_  ,\n",
    "                          }  )\n",
    "#i order the features according to their importance, and keep only the 20 best\n",
    "testDF = testDF.sort_values(by=['importance'] , ascending=True)[-20:]\n",
    "\n",
    "#color for the graph, not improtant\n",
    "palette = sns.color_palette(\"rocket\",n_colors = 50)\n",
    "\n",
    "#i do a bar plot with the gini score in X axis and name of the features on  Y axis\n",
    "#note : i 'normalize' the gini score obtained by the minimal value\n",
    "#i did this first by intuition looking at the original fiure as the gini score start to 1, and the result i obatined were very similar to the figure\n",
    "plt.barh(testDF['variables'],testDF['importance']/testDF['importance'].min(),color = palette  )\n",
    "#i set the limit a bit further than the max and min value \n",
    "plt.xlim([0.9,testDF['importance'].max()/testDF['importance'].min()+0.1])\n",
    "\n",
    "#set titles for the figure and the axis\n",
    "plt.title('Variables importance for Random Forest')\n",
    "plt.xlabel(\"Mean decrease in Gini Score\")\n",
    "plt.ylabel(\"Variables\")\n",
    "\n",
    "#i print the top 20 features (from worst to best) in cases its not readable on the figure\n",
    "print('-'+'\\n-'.join(map(str, testDF['variables'].values)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "\n",
    "X1 = doc_evol.drop(['warstds','year','cowcode','nmgdp','life','infant','expgdp','popdense','illiteracy'] , axis='columns')\n",
    "X2 = doc_evol.drop(['warstds','year','cowcode','evolnmgdp','evollife','evolinfant','evolexpgdp','evolpopdense','evolilliteracy'] , axis='columns')\n",
    "\n",
    "\n",
    "Xs = [ X , X1 , X2 ]\n",
    "Ys = [ y , y , y]\n",
    "rocList(clf,Xs,Ys,n=10,labels = ['with old + evol','with evol, not old','original'],displaymean = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features=['nmgdp','gdpgrowth','life','infant','expgdp','popdense','illiteracy']\n",
    "\n",
    "features = ['seceduc', 'pri', 'avgnabo', 'infant', 'ager',\n",
    "'ptime', 'ln_gdpen', 'nmgdp', 'popdense', 'expgdp',\n",
    "'lpopns', 'trade', 'manuexp', 'fuelexp', 'milper',\n",
    "'gdpgrowth', 'illiteracy' ,'agexp', 'sxpsq', 'sxpnew',\n",
    "'life','terrorism']\n",
    "\n",
    "scores=[]\n",
    "clf = RandomForestClassifier(n_estimators=100,max_depth=10)\n",
    "\n",
    "for ft in features:\n",
    "    \n",
    "    doc_copy = doc_t.drop('country',axis=1).copy()\n",
    "    doc_copy['evol'+ft] = computeEvol(doc_copy,ft)\n",
    "    #on retire les variables inutiles à la prediction\n",
    "    X = doc_copy.drop(['warstds','year','cowcode'] , axis='columns')\n",
    "    y = doc_copy['warstds']\n",
    "\n",
    "    #perform Random Forest mothod on the data\n",
    "    clf.fit(X,y)\n",
    "\n",
    "    #then i match the feature with their importance (aka Gini Score) provided by the Random Forest object\n",
    "    testDF = pd.DataFrame ( { 'variables' : X.columns ,\n",
    "                              'importance': clf.feature_importances_  ,\n",
    "                              }  )\n",
    "    \n",
    "    #i order the features according to their importance, and keep only the 20 best\n",
    "    testDF = testDF.sort_values(by=['importance'] , ascending=False)\n",
    "    testDF = testDF.reset_index()\n",
    "    \n",
    "    ind_ft = testDF.loc[ testDF['variables'] == ft].index[0]\n",
    "    ind_evol = testDF.loc[ testDF['variables'] == 'evol'+ft].index[0]\n",
    "    \n",
    "    scores.append( ind_ft - ind_evol )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF = pd.DataFrame ( { 'variables' : features ,\n",
    "                              'importance': scores  ,\n",
    "                              }  )\n",
    "    \n",
    "#i order the features according to their importance, and keep only the 20 best\n",
    "testDF = testDF.sort_values(by=['importance'] , ascending=False)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.barplot(y=testDF['variables'], x=testDF['importance'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = doc_t.drop( ['country','warstds','year','cowcode'], axis='columns' ).columns.values\n",
    "\n",
    "scores=[]\n",
    "clf = RandomForestClassifier(n_estimators=100,max_depth=10)\n",
    "\n",
    "for ft in features:\n",
    "    \n",
    "    doc_copy = doc_t.drop('country',axis=1).copy()\n",
    "    doc_copy['evol'+ft] = computeEvol(doc_copy,ft)\n",
    "    #on retire les variables inutiles à la prediction\n",
    "    X = doc_copy.drop(['warstds','year','cowcode'] , axis='columns')\n",
    "    y = doc_copy['warstds']\n",
    "\n",
    "    #perform Random Forest mothod on the data\n",
    "    clf.fit(X,y)\n",
    "\n",
    "    #then i match the feature with their importance (aka Gini Score) provided by the Random Forest object\n",
    "    testDF = pd.DataFrame ( { 'variables' : X.columns ,\n",
    "                              'importance': clf.feature_importances_  ,\n",
    "                              }  )\n",
    "    \n",
    "    #i order the features according to their importance, and keep only the 20 best\n",
    "    testDF = testDF.sort_values(by=['importance'] , ascending=False)\n",
    "    testDF = testDF.reset_index()\n",
    "    \n",
    "    ind_ft = testDF.loc[ testDF['variables'] == ft].index[0]\n",
    "    ind_evol = testDF.loc[ testDF['variables'] == 'evol'+ft].index[0]\n",
    "    \n",
    "    scores.append( ind_ft - ind_evol )\n",
    "    \n",
    "testDF = pd.DataFrame ( { 'variables' : features , 'importance': scores  , }  )\n",
    "    \n",
    "#i order the features according to their importance, and keep only the 20 best\n",
    "testDF = testDF.sort_values(by=['importance'] , ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,20))\n",
    "sns.barplot(y=testDF['variables'], x=testDF['importance'],)\n",
    "plt.title('Gain in rank of Gini Score for the Evolutions compared to original variables')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
